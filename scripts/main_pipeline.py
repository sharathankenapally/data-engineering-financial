# main_pipeline.py
from extract_data import extract_data
from transform_data import transform_data
from data_quality_check import data_quality_check
from load_data import load_data
from generate_report import generate_report
from visualize_report import visualize_report
from logger_setup import setup_logger
import os

# Initialize logger
logger = setup_logger()
logger.info("üè¶ Starting Financial Data Pipeline...")

try:
    # 1Ô∏è‚É£ Extract
    df = extract_data()
    logger.info(f"‚úÖ Extracted {df.shape[0]} records")

    # 2Ô∏è‚É£ Transform
    df = transform_data(df)
    logger.info("‚úÖ Transformation complete")

    # 3Ô∏è‚É£ Data Quality Check
    if not data_quality_check(df):
        logger.error("‚ö†Ô∏è Data Quality Check Failed. Pipeline stopped.")
        exit()

    # 4Ô∏è‚É£ Load into SQLite
    load_data(df)
    logger.info("‚úÖ Data successfully loaded into SQLite database")

    # 5Ô∏è‚É£ Generate summary reports
    generate_report(df)

    # Get latest report files
    reports_dir = os.path.join(os.path.dirname(__file__), '..', 'reports')
    summary_file = max(
        [os.path.join(reports_dir, f) for f in os.listdir(reports_dir) if f.startswith('summary_report_')],
        key=os.path.getctime
    )
    monthly_file = max(
        [os.path.join(reports_dir, f) for f in os.listdir(reports_dir) if f.startswith('monthly_summary_')],
        key=os.path.getctime
    )

    # 6Ô∏è‚É£ Create visualization
    visualize_report(summary_file, monthly_file)
    logger.info("Visualization created successfully")
    logger.info("Pipeline finished successfully!")

except Exception as e:
    logger.exception(f"Pipeline failed due to error: {e}")
